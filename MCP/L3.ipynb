{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c10b768-f5b4-43bc-a785-99077422ce78",
   "metadata": {},
   "source": [
    "# Lesson 3: Chatbot Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4fedc-4b90-4754-9f2d-fd3cfa321a14",
   "metadata": {},
   "source": [
    "In this lesson, you will familiarize yourself with the chatbot example you will work on during this course. The example includes the tool definitions and execution, as well as the chatbot code. Make sure to interact with the chatbot at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed96ba-5ade-4af4-9096-406ce48d5cf2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "dd6bd1d4-f652-45d1-9efa-155a2cc01713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T11:11:59.874984Z",
     "start_time": "2025-06-22T11:11:59.872080Z"
    }
   },
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "f20f163a-87af-4e0c-87ed-1624c150c572",
   "metadata": {},
   "source": [
    "## Tool Functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "549a7f46-74b3-4a1d-b084-055c99e3c318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T11:11:59.968855Z",
     "start_time": "2025-06-22T11:11:59.965814Z"
    }
   },
   "source": [
    "PAPER_DIR = \"papers\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "9e43905e-56f3-404c-a322-f038055e9b1c",
   "metadata": {},
   "source": [
    "The first tool searches for relevant arXiv papers based on a topic and stores the papers' info in a JSON file (title, authors, summary, paper url and the publication date). The JSON files are organized by topics in the `papers` directory. The tool does not download the papers.  "
   ]
  },
  {
   "cell_type": "code",
   "id": "8b2ef809-8514-46e0-b5cf-eff283bbda6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T11:12:00.023545Z",
     "start_time": "2025-06-22T11:12:00.015218Z"
    }
   },
   "source": [
    "# Use arxiv to find the papers \n",
    "client = arxiv.Client()\n",
    "\n",
    "# Search for the most relevant articles matching the queried topic\n",
    "search = arxiv.Search(\n",
    "    query = \"computers\",\n",
    "    max_results = 5,\n",
    "    sort_by = arxiv.SortCriterion.Relevance\n",
    ")\n",
    "search"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arxiv.Search(query='computers', id_list=[], max_results=5, sort_by=<SortCriterion.Relevance: 'relevance'>, sort_order=<SortOrder.Descending: 'descending'>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "ed129f5f-e0d5-45b4-949e-f683b1bdd94f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T11:12:00.990994Z",
     "start_time": "2025-06-22T11:12:00.102946Z"
    }
   },
   "source": [
    "papers = client.results(search)\n",
    "list(papers)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[arxiv.Result(entry_id='http://arxiv.org/abs/1310.7911v2', updated=datetime.datetime(2013, 12, 9, 21, 56, 24, tzinfo=datetime.timezone.utc), published=datetime.datetime(2013, 10, 29, 18, 29, 13, tzinfo=datetime.timezone.utc), title='Compact manifolds with computable boundaries', authors=[arxiv.Result.Author('Zvonko Iljazovic')], summary='We investigate conditions under which a co-computably enumerable closed set\\nin a computable metric space is computable and prove that in each locally\\ncomputable computable metric space each co-computably enumerable compact\\nmanifold with computable boundary is computable. In fact, we examine the notion\\nof a semi-computable compact set and we prove a more general result: in any\\ncomputable metric space each semi-computable compact manifold with computable\\nboundary is computable. In particular, each semi-computable compact\\n(boundaryless) manifold is computable.', comment=None, journal_ref='Logical Methods in Computer Science, Volume 9, Issue 4 (December\\n  11, 2013) lmcs:891', doi='10.2168/LMCS-9(4:19)2013', primary_category='cs.LO', categories=['cs.LO', 'math.LO'], links=[arxiv.Result.Link('http://dx.doi.org/10.2168/LMCS-9(4:19)2013', title='doi', rel='related', content_type=None), arxiv.Result.Link('http://arxiv.org/abs/1310.7911v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/1310.7911v2', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/math/9711204v1', updated=datetime.datetime(1997, 11, 25, 0, 0, tzinfo=datetime.timezone.utc), published=datetime.datetime(1997, 11, 25, 0, 0, tzinfo=datetime.timezone.utc), title='Aspects of Computability in Physics', authors=[arxiv.Result.Author('Joseph Shipman')], summary='This paper reviews connections between physics and computation, and explores\\ntheir implications. The main topics are computational \"hardness\" of physical\\nsystems, computational status of fundamental theories, quantum computation, and\\nthe Universe as a computer.', comment=None, journal_ref=None, doi=None, primary_category='math.LO', categories=['math.LO'], links=[arxiv.Result.Link('http://arxiv.org/abs/math/9711204v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/math/9711204v1', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/2208.00733v1', updated=datetime.datetime(2022, 8, 1, 10, 36, 13, tzinfo=datetime.timezone.utc), published=datetime.datetime(2022, 8, 1, 10, 36, 13, tzinfo=datetime.timezone.utc), title='The Rise of Quantum Internet Computing', authors=[arxiv.Result.Author('Seng W. Loke')], summary='This article highlights quantum Internet computing as referring to\\ndistributed quantum computing over the quantum Internet, analogous to\\n(classical) Internet computing involving (classical) distributed computing over\\nthe (classical) Internet. Relevant to quantum Internet computing would be areas\\nof study such as quantum protocols for distributed nodes using quantum\\ninformation for computations, quantum cloud computing, delegated verifiable\\nblind or private computing, non-local gates, and distributed quantum\\napplications, over Internet-scale distances.', comment=None, journal_ref=None, doi=None, primary_category='cs.ET', categories=['cs.ET', 'cs.DC'], links=[arxiv.Result.Link('http://arxiv.org/abs/2208.00733v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2208.00733v1', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/2504.07020v1', updated=datetime.datetime(2025, 4, 9, 16, 36, 11, tzinfo=datetime.timezone.utc), published=datetime.datetime(2025, 4, 9, 16, 36, 11, tzinfo=datetime.timezone.utc), title='Computably discrete represented spaces', authors=[arxiv.Result.Author('Eike Neumann'), arxiv.Result.Author('Arno Pauly'), arxiv.Result.Author('Cécilia Pradic'), arxiv.Result.Author('Manlio Valenti')], summary='In computable topology, a represented space is called computably discrete if\\nits equality predicate is semidecidable. While any such space is classically\\nisomorphic to an initial segment of the natural numbers, the\\ncomputable-isomorphism types of computably discrete represented spaces exhibit\\na rich structure. We show that the widely studied class of computably\\nenumerable equivalence relations (ceers) corresponds precisely to the\\ncomputably Quasi-Polish computably discrete spaces. We employ computably\\ndiscrete spaces to exhibit several separating examples in computable topology.\\nWe construct a computably discrete computably Quasi-Polish space admitting no\\ndecidable properties, a computably discrete and computably Hausdorff\\nprecomputably Quasi-Polish space admitting no computable injection into the\\nnatural numbers, a two-point space which is computably Hausdorff but not\\ncomputably discrete, and a two-point space which is computably discrete but not\\ncomputably Hausdorff. We further expand an example due to Weihrauch that\\nseparates computably regular spaces from computably normal spaces.', comment=None, journal_ref=None, doi=None, primary_category='math.LO', categories=['math.LO', 'cs.LO', 'math.GN', '54G20, 54D15, 03F60, 03D78'], links=[arxiv.Result.Link('http://arxiv.org/abs/2504.07020v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2504.07020v1', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/2403.03925v1', updated=datetime.datetime(2024, 3, 6, 18, 37, 6, tzinfo=datetime.timezone.utc), published=datetime.datetime(2024, 3, 6, 18, 37, 6, tzinfo=datetime.timezone.utc), title='Consciousness qua Mortal Computation', authors=[arxiv.Result.Author('Johannes Kleiner')], summary='Computational functionalism posits that consciousness is a computation. Here\\nwe show, perhaps surprisingly, that it cannot be a Turing computation. Rather,\\ncomputational functionalism implies that consciousness is a novel type of\\ncomputation that has recently been proposed by Geoffrey Hinton, called mortal\\ncomputation.', comment=None, journal_ref=None, doi=None, primary_category='q-bio.NC', categories=['q-bio.NC', 'cs.AI'], links=[arxiv.Result.Link('http://arxiv.org/abs/2403.03925v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2403.03925v1', title='pdf', rel='related', content_type=None)])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "886633b8-ce67-4343-822d-cc3f98f953fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T11:12:01.059080Z",
     "start_time": "2025-06-22T11:12:01.050919Z"
    }
   },
   "source": [
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "\n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "\n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "\n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "\n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "\n",
    "    return paper_ids"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "d20ee17a-afe6-438a-95b1-6e87742c7fac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T11:12:02.059037Z",
     "start_time": "2025-06-22T11:12:01.089916Z"
    }
   },
   "source": [
    "search_papers(\"computers\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers/computers/papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1310.7911v2',\n",
       " 'math/9711204v1',\n",
       " '2208.00733v1',\n",
       " '2504.07020v1',\n",
       " '2403.03925v1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "dfb83565-69af-47f3-9ba3-a96965cff7df",
   "metadata": {},
   "source": [
    "The second tool looks for information about a specific paper across all topic directories inside the `papers` directory."
   ]
  },
  {
   "cell_type": "code",
   "id": "df9b1997-81cd-447d-9665-1cb72d93bb9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T11:12:02.098620Z",
     "start_time": "2025-06-22T11:12:02.090773Z"
    }
   },
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    "\n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "0ebe0de7-8f07-4e08-a670-7b371fc3d2d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T11:12:02.170420Z",
     "start_time": "2025-06-22T11:12:02.165035Z"
    }
   },
   "source": [
    "extract_info('1310.7911v2')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"Compact manifolds with computable boundaries\",\\n  \"authors\": [\\n    \"Zvonko Iljazovic\"\\n  ],\\n  \"summary\": \"We investigate conditions under which a co-computably enumerable closed set\\\\nin a computable metric space is computable and prove that in each locally\\\\ncomputable computable metric space each co-computably enumerable compact\\\\nmanifold with computable boundary is computable. In fact, we examine the notion\\\\nof a semi-computable compact set and we prove a more general result: in any\\\\ncomputable metric space each semi-computable compact manifold with computable\\\\nboundary is computable. In particular, each semi-computable compact\\\\n(boundaryless) manifold is computable.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/1310.7911v2\",\\n  \"published\": \"2013-10-29\"\\n}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "b5ea3013-e690-4bc8-8622-27b4d42d61e4",
   "metadata": {},
   "source": [
    "## Tool Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d2260-452d-472a-b56e-326479cb18c9",
   "metadata": {},
   "source": [
    "Here are the schema of each tool which you will provide to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "id": "e5bdea5f-e93a-4018-8c13-00d5ee10c0b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T11:12:02.243996Z",
     "start_time": "2025-06-22T11:12:02.239339Z"
    }
   },
   "source": [
    "tools = [\n",
    "    {   \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_papers\",\n",
    "            \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"topic\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The topic to search for\"\n",
    "                    },\n",
    "                    \"max_results\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Maximum number of results to retrieve\",\n",
    "                        \"default\": 5\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"topic\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {   \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"extract_info\",\n",
    "            \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"paper_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The ID of the paper to look for\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"paper_id\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "ec668d24-1559-41b7-bc8a-e2dca77dfaf2",
   "metadata": {},
   "source": [
    "## Tool Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728c1ec-36b1-48b4-9f85-622464ac79f4",
   "metadata": {},
   "source": [
    "This code handles tool mapping and execution."
   ]
  },
  {
   "cell_type": "code",
   "id": "c90790c0-efc4-4068-9c00-d2592d80bc30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T11:12:02.302360Z",
     "start_time": "2025-06-22T11:12:02.298012Z"
    }
   },
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name, tool_args):\n",
    "\n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "    if result is None:\n",
    "        result = \"The operation completed but didn't return any results.\"\n",
    "\n",
    "    elif isinstance(result, list):\n",
    "        result = ', '.join(result)\n",
    "\n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "\n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "4d8fc4d3-58ac-482c-8bbd-bccd6ef9fc31",
   "metadata": {},
   "source": [
    "## Chatbot Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba0fad-b0e4-4415-a431-341e9ca85087",
   "metadata": {},
   "source": [
    "The chatbot handles the user's queries one by one, but it does not persist memory across the queries."
   ]
  },
  {
   "cell_type": "code",
   "id": "fe662400-8506-464e-a3da-75a3d8848bac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T11:12:03.141176Z",
     "start_time": "2025-06-22T11:12:02.339720Z"
    }
   },
   "source": [
    "load_dotenv()\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "175586b4-acdf-4103-8039-134478a4f797",
   "metadata": {},
   "source": [
    "### Query Processing"
   ]
  },
  {
   "cell_type": "code",
   "id": "12a896e0-3f56-417e-aa51-c61756048593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T11:22:39.432344Z",
     "start_time": "2025-06-22T11:22:39.426823Z"
    }
   },
   "source": [
    "def function_calling(messages):\n",
    "    completion = client.chat.completions.create(\n",
    "        max_tokens = 2024,\n",
    "        model=\"qwen-plus\",  # 此处以qwen-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "    return completion\n",
    "\n",
    "def process_query(query):\n",
    "\n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "\n",
    "    process_query = True\n",
    "    while process_query:\n",
    "        completion = function_calling(messages)\n",
    "        if completion.choices[0].message.content:\n",
    "            print(completion.choices[0].message.content)\n",
    "            process_query = False\n",
    "\n",
    "        elif len(completion.choices[0].message.tool_calls) > 0:\n",
    "            tool_calls = completion.choices[0].message.tool_calls\n",
    "            tool_name = tool_calls[0].function.name\n",
    "            tool_args = tool_calls[0].function.arguments\n",
    "            tool_args = json.loads(tool_args)\n",
    "            print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "            result = execute_tool(tool_name, tool_args)\n",
    "            messages.append(completion.choices[0].message)\n",
    "            messages.append({\"role\": \"tool\", \"content\": result, \"tool_call_id\": tool_calls[0].id})"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "2921ee7f-d2be-464b-ab7b-8db2a3c13ba9",
   "metadata": {},
   "source": [
    "### Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "id": "16979cdc-81e9-432b-ba7f-e810b52961e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T11:22:42.007812Z",
     "start_time": "2025-06-22T11:22:42.004379Z"
    }
   },
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "\n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "1cfaf254-f22a-4951-885e-1d21fbc41ff3",
   "metadata": {},
   "source": [
    "Feel free to interact with the chatbot. Here's an example query: \n",
    "\n",
    "- Search for 2 papers on \"LLM interpretability\"\n",
    "\n",
    "To access the `papers` folder: 1) click on the `File` option on the top menu of the notebook and 2) click on `Open` and then 3) click on `L3`."
   ]
  },
  {
   "cell_type": "code",
   "id": "39676f70-1c72-4da3-8363-da281bd5a83e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T11:26:35.635121Z",
     "start_time": "2025-06-22T11:22:50.877933Z"
    }
   },
   "source": [
    "chat_loop()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n",
      "Calling tool search_papers with args {'topic': 'LLM interpretability', 'max_results': 2}\n",
      "Results are saved in: papers/llm_interpretability/papers_info.json\n",
      "I found two papers on \"LLM interpretability\". Here are their IDs:\n",
      "\n",
      "1. Paper ID: 2412.07992v3\n",
      "2. Paper ID: 2402.01761v1\n",
      "\n",
      "If you need more information about these papers, please let me know!\n",
      "\n",
      "\n",
      "It seems like you might be asking for a summary of two specific papers, but your request is a bit unclear. Could you please clarify which two papers you would like summarized? If you have the IDs or topics of the papers in question, please provide them. This will help me give you the information you're looking for. If you want, I can search for papers based on a topic or extract information about specific papers by their ID. What would you like to do?\n",
      "\n",
      "\n",
      "Calling tool extract_info with args {'paper_id': '2412.07992v3'}\n",
      "Calling tool extract_info with args {'paper_id': '2402.01761v1'}\n",
      "Here are the details for the two papers you asked about:\n",
      "\n",
      "The first paper is titled \"Concept Bottleneck Large Language Models\". It was authored by Chung-En Sun, Tuomas Oikarinen, Berk Ustun, and Tsui-Wei Weng. The summary reads: We introduce Concept Bottleneck Large Language Models (CB-LLMs), a novel framework for building inherently interpretable Large Language Models (LLMs). In contrast to traditional black-box LLMs that rely on limited post-hoc interpretations, CB-LLMs integrate intrinsic interpretability directly into the LLMs -- allowing accurate explanations with scalability and transparency. We build CB-LLMs for two essential NLP tasks: text classification and text generation. In text classification, CB-LLMs is competitive with, and at times outperforms, traditional black-box models while providing explicit and interpretable reasoning. For the more challenging task of text generation, interpretable neurons in CB-LLMs enable precise concept detection, controlled generation, and safer outputs. The embedded interpretability empowers users to transparently identify harmful content, steer model behavior, and unlearn undesired concepts -- significantly enhancing the safety, reliability, and trustworthiness of LLMs, which are critical capabilities notably absent in existing models. Our code is available at https://github.com/Trustworthy-ML-Lab/CB-LLMs. You can find the PDF [here](http://arxiv.org/pdf/2412.07992v3). This paper was published on 2024-12-11.\n",
      "\n",
      "The second paper is titled \"Rethinking Interpretability in the Era of Large Language Models\". The authors are Chandan Singh, Jeevana Priya Inala, Michel Galley, Rich Caruana, and Jianfeng Gao. The summary states: Interpretable machine learning has exploded as an area of interest over the last decade, sparked by the rise of increasingly large datasets and deep neural networks. Simultaneously, large language models (LLMs) have demonstrated remarkable capabilities across a wide array of tasks, offering a chance to rethink opportunities in interpretable machine learning. Notably, the capability to explain in natural language allows LLMs to expand the scale and complexity of patterns that can be given to a human. However, these new capabilities raise new challenges, such as hallucinated explanations and immense computational costs. In this position paper, we start by reviewing existing methods to evaluate the emerging field of LLM interpretation (both interpreting LLMs and using LLMs for explanation). We contend that, despite their limitations, LLMs hold the opportunity to redefine interpretability with a more ambitious scope across many applications, including in auditing LLMs themselves. We highlight two emerging research priorities for LLM interpretation: using LLMs to directly analyze new datasets and to generate interactive explanations. You can access the PDF [here](http://arxiv.org/pdf/2402.01761v1). This paper was published on 2024-01-30.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T11:30:27.289853Z",
     "start_time": "2025-06-22T11:29:32.556191Z"
    }
   },
   "cell_type": "code",
   "source": "chat_loop()",
   "id": "b8338caea230bcf4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "\n",
      "I currently have two tools at my disposal:\n",
      "\n",
      "1. `search_papers`: This function allows me to search for papers on arXiv based on a specified topic and then store their information. It requires the input parameters such as the topic to search for and the maximum number of results to retrieve (with a default of 5).\n",
      "\n",
      "2. `extract_info`: This function is used to search for information about a specific paper across all topic directories. It requires the input parameter of the paper ID to look for.\n",
      "\n",
      "Would you like to use either of these functions to find a paper or extract information about a specific one? If so, please provide me with the necessary details!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "d02d207b-e07d-49ff-bb03-7954aa86c167",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "[Guide on how to implement tool use](https://docs.anthropic.com/en/docs/build-with-claude/tool-use/overview#how-to-implement-tool-use)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
